# Q-Learning Agent pro FrozenLake (Gymnasium)

Tento projekt implementuje **Q-learning** agenta, kterÃ½ se uÄÃ­ Å™eÅ¡it prostÅ™edÃ­ **FrozenLake-v1** z knihovny [Gymnasium](https://gymnasium.farama.org/).  
Obsahuje kompletnÃ­ pipeline od trÃ©ninku, pÅ™es vyhodnocenÃ­ aÅ¾ po vizualizaci nauÄenÃ©ho chovÃ¡nÃ­.

---

## ğŸ“‚ Struktura projektu

```
.
â”œâ”€â”€ agent.py         # Implementace Q-learning agenta
â”œâ”€â”€ environment.py   # Wrapper pro prostÅ™edÃ­ FrozenLake
â”œâ”€â”€ history.py       # UklÃ¡dÃ¡nÃ­ Q-tabulek a grafÅ¯ odmÄ›n
â”œâ”€â”€ main.py          # HlavnÃ­ skript pro spuÅ¡tÄ›nÃ­ trÃ©ninku, evaluace a vizualizace
â”œâ”€â”€ train.py         # TrÃ©ninkovÃ¡ smyÄka a evaluace agenta
â”œâ”€â”€ visualize.py     # Vizualizace chovÃ¡nÃ­ nauÄenÃ©ho agenta
â”œâ”€â”€ requirements.txt # ZÃ¡vislosti projektu
```

---

## ğŸš€ Instalace

1. **VytvoÅ™enÃ­ a aktivace virtuÃ¡lnÃ­ho prostÅ™edÃ­** (doporuÄeno):
   ```bash
   python -m venv venv
   source venv/bin/activate   # Linux / macOS
   venv\Scripts\activate      # Windows
   ```

2. **Instalace zÃ¡vislostÃ­**:
   ```bash
   pip install -r requirements.txt
   ```

---

## âš™ï¸ SpuÅ¡tÄ›nÃ­ trÃ©ninku

HlavnÃ­ skript `main.py` provede:
1. Inicializaci prostÅ™edÃ­ a agenta  
2. TrÃ©nink na zadanÃ½ poÄet epizod  
3. VyhodnocenÃ­ ÃºspÄ›Å¡nosti  
4. UloÅ¾enÃ­ Q-tabulek a grafÅ¯  
5. Vizualizaci chovÃ¡nÃ­ agenta

SpuÅ¡tÄ›nÃ­:
```bash
python main.py
```

Parametry pro trÃ©nink (mapa, poÄet epizod, epsilon decay apod.) lze upravit pÅ™Ã­mo v `main.py`:
```python
MAP_NAME = "8x8"        # velikost mapy
IS_SLIPPERY = True      # zda je led klouzavÃ½
EPISODES = 200000       # poÄet trÃ©ninkovÃ½ch epizod
ALPHA = 0.2             # learning rate
GAMMA = 0.95            # discount faktor
```

---

## ğŸ“Š VÃ½stupy

Po trÃ©ninku se vygenerujÃ­:
- **Q-tabule** (`.npy` a `.csv`) â€“ uloÅ¾enÃ© v `lecture9/q_tables/`
- **Graf prÅ¯bÄ›hu odmÄ›n** (`.png`) â€“ uloÅ¾enÃ½ v `lecture9/figures/`
- **VÃ½pis evaluace** v konzoli
- **Vizualizace bÄ›hu agenta** v oknÄ› prostÅ™edÃ­

---

## ğŸ§  Jak funguje Q-learning v tomto projektu
- Agent se uÄÃ­ **hodnoty stav-akce** (Q-values) na zÃ¡kladÄ› zÃ­skanÃ½ch odmÄ›n
- PouÅ¾Ã­vÃ¡ **Îµ-greedy** strategii pro vyvaÅ¾ovÃ¡nÃ­ prÅ¯zkumu a vyuÅ¾itÃ­
- Aktualizace Q-tabulek podle vzorce:
  \[
  Q(s,a) \leftarrow Q(s,a) + \alpha \cdot \left[ r + \gamma \cdot \max_{a'} Q(s', a') - Q(s,a) \right]
  \]
- Epsilon se postupnÄ› sniÅ¾uje pomocÃ­ `epsilon_decay`

---

## ğŸ“¦ PoÅ¾adavky
HlavnÃ­ knihovny:
- `gymnasium` â€“ prostÅ™edÃ­ FrozenLake
- `numpy` â€“ prÃ¡ce s Q-tabulkou
- `matplotlib` â€“ vizualizace odmÄ›n
- `pygame` â€“ render prostÅ™edÃ­

PodrobnÃ½ seznam je v [`requirements.txt`](requirements.txt).

---
